[checking]
robotstxt=1

[filtering]
checkextern=1
ignore=
    \/\/localhost
    \/\/127.0.0.1
    \/\/www.ssllabs.com
    \/\/www.imy.se
    \/\/packages.ubuntu.com
    \/\/regexr.com
    # The pages below fail AnchorCheck as they create
    # anchor's dynamically.
    \/\/github.com
    \/\/registry.terraform.io
    \/\/kubespray.io
    \/\/www.oreilly.com
    \/\/inera.atlassian.net
ignorewarnings=http-redirected
ignorewarningsforurls=
  ^https://stackoverflow.com ^http-rate-limited

[output]
ignoreerrors=
    # Avoid being someone else's uptime monitor :)
    ^https:// ^ReadTimeout

[AnchorCheck]

[PdfParser]
